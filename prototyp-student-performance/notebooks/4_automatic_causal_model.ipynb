{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef91bdff-9bec-4fa5-a668-aaaa9ad674b7",
   "metadata": {},
   "source": [
    "## 4. Defining a Causal Model using automatic Causal Discovery\n",
    "\n",
    "The fourth step is to construct a causal model that involves identifying the relationships between variables to understand how they influence Exam_Score. \n",
    "This will be achieved by creating a Directed Acyclic Graph (DAG) that visually represents these relationships using automatiec Causal Discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ba545f-6a27-4c9f-b8e9-28a720d0b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from graphviz import Digraph\n",
    "import dowhy\n",
    "from dowhy import gcm\n",
    "from dowhy import CausalModel\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import graphviz\n",
    "from causallearn.utils.GraphUtils import GraphUtils\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.search.ScoreBased.GES import ges\n",
    "from causallearn.search.FCMBased import lingam\n",
    "import matplotlib.image as mpimg\n",
    "import io\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b70822-7234-4f0e-a070-38dc0cad2cd6",
   "metadata": {},
   "source": [
    "### Load the preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dab87f4-bec9-4a7d-93a9-564a1f5fcce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.read_csv('../data/encoded_student_performance_factors.csv')\n",
    "# df_cleaned = pd.read_csv('../data/cleaned_student_performance_factors.csv')\n",
    "labels = df_encoded.columns.tolist()\n",
    "data = df_encoded.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d6fca-0ba4-4784-af59-3737251d225d",
   "metadata": {},
   "source": [
    "### Identify Potential Causal Relationships using automatic Causal Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fd8b6b2-3e14-4c1a-ba3e-f6c3da143e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion für Plotting\n",
    "def plot_dag(graph_dot, title):\n",
    "    graph = graphviz.Source(graph_dot)\n",
    "    graph.render(filename=title, format='png', cleanup=True)\n",
    "\n",
    "def fix_pydot_labels(dot_str):\n",
    "    \"\"\"\n",
    "    Bereinigt DOT-Strings aus GraphUtils, sodass Labels direkt als Knotennamen verwendet werden.\n",
    "    \"\"\"\n",
    "    lines = dot_str.splitlines()\n",
    "    label_dict = {}\n",
    "\n",
    "    # Schritt 1: Label Dictionary erstellen\n",
    "    for line in lines:\n",
    "        match = re.match(r'\\s*(\\d+)\\s*\\[label=\"?([^\"\\]]+)\"?\\];', line)\n",
    "        if match:\n",
    "            node_id, label = match.groups()\n",
    "            label_dict[node_id] = label.strip('\"')\n",
    "\n",
    "    # Schritt 2: Nur Kantenzeilen auswählen und Knoten ersetzen\n",
    "    corrected_lines = [\"digraph {\"]\n",
    "\n",
    "    # Labels anfügen\n",
    "    for node_id, label in label_dict.items():\n",
    "        corrected_lines.append(f'{label}')\n",
    "\n",
    "    # Kanten extrahieren\n",
    "    for line in lines:\n",
    "        if '->' in line:\n",
    "            for node_id, label in label_dict.items():\n",
    "                line = re.sub(rf'\\b{node_id}\\b', f'{label}', line)\n",
    "            corrected_lines.append(line)\n",
    "\n",
    "    corrected_lines.append(\"}\")\n",
    "\n",
    "    return '\\n'.join(corrected_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db11f133-9f69-4f66-97ea-581134ab9d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth=14, working on node 19: 100%|██████████| 20/20 [00:00<00:00, 1407.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "Hours_Studied\n",
      "Attendance\n",
      "Parental_Involvement\n",
      "Access_to_Resources\n",
      "Extracurricular_Activities\n",
      "Sleep_Hours\n",
      "Previous_Scores\n",
      "Motivation_Level\n",
      "Internet_Access\n",
      "Tutoring_Sessions\n",
      "Family_Income\n",
      "Teacher_Quality\n",
      "School_Type\n",
      "Peer_Influence\n",
      "Physical_Activity\n",
      "Learning_Disabilities\n",
      "Parental_Education_Level\n",
      "Distance_from_Home\n",
      "Gender\n",
      "Exam_Score\n",
      "Hours_Studied -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Attendance -> Parental_Education_Level [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Attendance -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Parental_Involvement -> Access_to_Resources [dir=both, arrowtail=none, arrowhead=none];\n",
      "Parental_Involvement -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Access_to_Resources -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Extracurricular_Activities -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Previous_Scores -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Motivation_Level -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Internet_Access -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Tutoring_Sessions -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Family_Income -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Teacher_Quality -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Peer_Influence -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Physical_Activity -> Parental_Education_Level [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Learning_Disabilities -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Exam_Score -> Parental_Education_Level [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Distance_from_Home -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 1. PC Algorithmus DAG visualisieren\n",
    "pc_graph = pc(data)\n",
    "pc_dot = GraphUtils.to_pydot(pc_graph.G, labels=labels).to_string()\n",
    "pc_dot_fixed = fix_pydot_labels(pc_dot)\n",
    "plot_dag(pc_dot_fixed, \"../causal-model/automatic-causal-models/pc_dag\")\n",
    "print(pc_dot_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38a3f72d-2177-4ee7-a60c-48916e67e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "Hours_Studied\n",
      "Attendance\n",
      "Parental_Involvement\n",
      "Access_to_Resources\n",
      "Extracurricular_Activities\n",
      "Sleep_Hours\n",
      "Previous_Scores\n",
      "Motivation_Level\n",
      "Internet_Access\n",
      "Tutoring_Sessions\n",
      "Family_Income\n",
      "Teacher_Quality\n",
      "School_Type\n",
      "Peer_Influence\n",
      "Physical_Activity\n",
      "Learning_Disabilities\n",
      "Parental_Education_Level\n",
      "Distance_from_Home\n",
      "Gender\n",
      "Exam_Score\n",
      "Hours_Studied -> Distance_from_Home [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Hours_Studied -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Attendance -> Distance_from_Home [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Attendance -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Parental_Involvement -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Access_to_Resources -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Exam_Score -> Extracurricular_Activities [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Previous_Scores -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Motivation_Level -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Tutoring_Sessions -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Family_Income -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Teacher_Quality -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Peer_Influence -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Exam_Score -> Learning_Disabilities [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Parental_Education_Level -> Exam_Score [dir=both, arrowtail=none, arrowhead=normal];\n",
      "Exam_Score -> Distance_from_Home [dir=both, arrowtail=none, arrowhead=normal];\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 2. GES Algorithmus DAG visualisieren\n",
    "ges_graph = ges(data)['G']\n",
    "ges_dot = GraphUtils.to_pydot(ges_graph, labels=labels).to_string()\n",
    "ges_dot_fixed = fix_pydot_labels(ges_dot)\n",
    "plot_dag(ges_dot_fixed, \"../causal-model/automatic-causal-models/ges_dag\")\n",
    "print(ges_dot_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a141691-e1c6-4d69-8ae3-89b3125afdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\tHours_Studied\n",
      "\tAttendance\n",
      "\tParental_Involvement\n",
      "\tAccess_to_Resources\n",
      "\tExtracurricular_Activities\n",
      "\tSleep_Hours\n",
      "\tPrevious_Scores\n",
      "\tMotivation_Level\n",
      "\tInternet_Access\n",
      "\tTutoring_Sessions\n",
      "\tFamily_Income\n",
      "\tTeacher_Quality\n",
      "\tSchool_Type\n",
      "\tPeer_Influence\n",
      "\tPhysical_Activity\n",
      "\tLearning_Disabilities\n",
      "\tParental_Education_Level\n",
      "\tDistance_from_Home\n",
      "\tGender\n",
      "\tExam_Score\n",
      "\tHours_Studied -> Exam_Score [label=0.29]\n",
      "\tAttendance -> Exam_Score [label=0.20]\n",
      "\tParental_Involvement -> Exam_Score [label=1.00]\n",
      "\tAccess_to_Resources -> Exam_Score [label=1.03]\n",
      "\tExtracurricular_Activities -> Exam_Score [label=0.55]\n",
      "\tPrevious_Scores -> Exam_Score [label=0.05]\n",
      "\tMotivation_Level -> Exam_Score [label=0.53]\n",
      "\tInternet_Access -> Exam_Score [label=0.91]\n",
      "\tTutoring_Sessions -> Exam_Score [label=0.50]\n",
      "\tFamily_Income -> Exam_Score [label=0.53]\n",
      "\tTeacher_Quality -> Exam_Score [label=0.53]\n",
      "\tPeer_Influence -> Exam_Score [label=0.51]\n",
      "\tPhysical_Activity -> Exam_Score [label=0.18]\n",
      "\tLearning_Disabilities -> Exam_Score [label=0.84]\n",
      "\tParental_Education_Level -> Exam_Score [label=0.49]\n",
      "\tDistance_from_Home -> Exam_Score [label=0.47]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\anaconda3\\envs\\master-thesis-prototyp\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. LiNGAM Algorithmus DAG visualisieren\n",
    "lingam_model = lingam.ICALiNGAM()\n",
    "lingam_model.fit(data)\n",
    "\n",
    "def make_graph(adjacency_matrix, labels):\n",
    "    idx = np.abs(adjacency_matrix) > 0.01\n",
    "    dirs = np.where(idx)\n",
    "    d = graphviz.Digraph(engine='dot')\n",
    "    for name in labels:\n",
    "        d.node(name)\n",
    "    for to, from_, coef in zip(dirs[0], dirs[1], adjacency_matrix[idx]):\n",
    "        d.edge(labels[from_], labels[to], label=f\"{coef:.2f}\")\n",
    "    return d\n",
    "\n",
    "lingam_dot = make_graph(lingam_model.adjacency_matrix_, labels).source\n",
    "plot_dag(lingam_dot, \"../causal-model/automatic-causal-models/lingam_dag\")\n",
    "print(lingam_dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bef63-ac83-48c9-bf3a-8982d40eb56a",
   "metadata": {},
   "source": [
    "### Kausale Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa6a9b68-d758-4969-ab5f-e283ce2f4221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Angepasste Funktionen zur kausalen Analyse\n",
    "def create_causal_model(graph_dot, df, treatment, outcome): \n",
    "    model = CausalModel(\n",
    "        data=df,\n",
    "        treatment=treatment,\n",
    "        outcome=outcome,\n",
    "        graph=graph_dot\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def do_causal_identification(model):\n",
    "    identified_estimand = model.identify_effect()\n",
    "    return identified_estimand\n",
    "\n",
    "def do_causal_estimation_propensity_score_stratification(model, identified_estimand):\n",
    "    estimate = model.estimate_effect(identified_estimand,\n",
    "                                 method_name=\"backdoor.propensity_score_stratification\")\n",
    "    return estimate\n",
    "\n",
    "def do_causal_estimation_linear_regression(model, identified_estimand):\n",
    "    estimate = model.estimate_effect(identified_estimand,\n",
    "                                 method_name=\"backdoor.linear_regression\")\n",
    "    return estimate\n",
    "\n",
    "# Refuting the estimate \n",
    "# -> Refutation methods provide tests that every correct estimator should pass. So if an estimator fails the refutation test (p-value is <0.05), then it means that there is some problem with the estimator.\n",
    "# -> We cannot verify that the estimate is correct but we can reject it if it violates certain expected behaviour \n",
    "# -> refutation tests are based on either Invariant transformations (changes in the data that should not change the estimate. Any estimator whose result varies significantly between the original data and the\n",
    "# modified data fails the test -> Random Common Cause or Data Subset) or Nullifying transformations (after the data changes, the causal true estimate is zero. Any estimator whose result varies significantly \n",
    "# from zero on the new data fails the test -> Placeabo Treatment)\n",
    "def do_causal_refute_estimate_random(model, identified_estimand, estimate):\n",
    "    refutation_random = model.refute_estimate(identified_estimand, estimate, method_name=\"random_common_cause\", show_progress_bar=True)\n",
    "    return refutation_random\n",
    "\n",
    "def do_causal_refute_estimate_placebo(model, identified_estimand, estimate):\n",
    "    res_placebo = model.refute_estimate(identified_estimand, estimate, method_name=\"placebo_treatment_refuter\", show_progress_bar=True, placebo_type=\"permute\")\n",
    "    return res_placebo\n",
    "\n",
    "def do_causal_refute_estimate_subset(model, identified_estimand, estimate):\n",
    "    res_subset = model.refute_estimate(identified_estimand, estimate, method_name=\"data_subset_refuter\", show_progress_bar=True, subset_fraction=0.9)\n",
    "    return res_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc3784-f182-4b08-9de8-5740cbfd2fb5",
   "metadata": {},
   "source": [
    "### PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "763421af-327b-47cc-a6e1-285acfebbb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PC DAG Causal Model\n",
    "pc_model = create_causal_model(pc_dot_fixed, df_encoded, treatment=\"Hours_Studied\", outcome=\"Exam_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f80bff63-195d-448b-9e04-8c06d4c5ee0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "       d                       \n",
      "────────────────(E[Exam_Score])\n",
      "d[Hours_Studied]               \n",
      "Estimand assumption 1, Unconfoundedness: If U→{Hours_Studied} and U→Exam_Score then P(Exam_Score|Hours_Studied,,U) = P(Exam_Score|Hours_Studied,)\n",
      "\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable(s) found!\n",
      "\n",
      "### Estimand : 3\n",
      "Estimand name: frontdoor\n",
      "No such variable(s) found!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pc_identified_estimand\n",
    "pc_identified_estimand = do_causal_identification(pc_model)\n",
    "print(pc_identified_estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49935827-4cd3-4def-b0ca-798d100923c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_do_causal_estimation_propensity_score_stratification\n",
    "pc_estimate_propensity_score = do_causal_estimation_propensity_score_stratification(pc_model, pc_identified_estimand)\n",
    "print(pc_estimate_propensity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d944b62-7f98-4729-bacb-cfc6b1ba6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_do_causal_estimation_linear_regression\n",
    "pc_estimate_linear_regression = do_causal_estimation_linear_regression(pc_model, pc_identified_estimand)\n",
    "print(pc_estimate_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da9af1-e4e9-438b-b900-67990801c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_do_causal_refute_estimate_random\n",
    "pc_refutation_random = do_causal_refute_estimate_random(pc_model, pc_identified_estimand, pc_estimate_linear_regression)\n",
    "print('pc_refutation_random: ', pc_refutation_random)\n",
    "\n",
    "# pc_do_causal_refute_estimate_placebo\n",
    "pc_res_placebo = do_causal_refute_estimate_placebo(pc_model, pc_identified_estimand, pc_estimate_linear_regression)\n",
    "print('pc_res_placebo: ', pc_res_placebo)\n",
    "\n",
    "# pc_do_causal_refute_estimate_subset\n",
    "pc_res_subset = do_causal_refute_estimate_subset(pc_model, pc_identified_estimand, pc_estimate_linear_regression)\n",
    "print('pc_res_subset: ', pc_res_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc86fc6-67e7-4ac4-af50-f340d12bc5e6",
   "metadata": {},
   "source": [
    "### GES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8b7fcec-83d4-4c82-9002-45723a4f548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GES DAG Causal Model\n",
    "ges_model = create_causal_model(ges_dot_fixed, df_encoded, treatment=\"Hours_Studied\", outcome=\"Exam_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "812d4131-364b-4959-848b-d42df5784127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "       d                       \n",
      "────────────────(E[Exam_Score])\n",
      "d[Hours_Studied]               \n",
      "Estimand assumption 1, Unconfoundedness: If U→{Hours_Studied} and U→Exam_Score then P(Exam_Score|Hours_Studied,,U) = P(Exam_Score|Hours_Studied,)\n",
      "\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable(s) found!\n",
      "\n",
      "### Estimand : 3\n",
      "Estimand name: frontdoor\n",
      "No such variable(s) found!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ges_identified_estimand\n",
    "ges_identified_estimand = do_causal_identification(ges_model)\n",
    "print(ges_identified_estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e05e5-3bff-4480-a5f5-4192abfd4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ges_do_causal_estimation_propensity_score_stratification\n",
    "ges_estimate_propensity_score = do_causal_estimation_propensity_score_stratification(ges_model, ges_identified_estimand)\n",
    "print(ges_estimate_propensity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ae77c-b3ed-4174-8ec4-715491d7817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ges_do_causal_estimation_linear_regression\n",
    "ges_estimate_linear_regression = do_causal_estimation_linear_regression(ges_model, ges_identified_estimand)\n",
    "print(ges_estimate_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfff44-e27a-4764-b852-0e5b0a95b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ges_do_causal_refute_estimate_random\n",
    "ges_refutation_random = do_causal_refute_estimate_random(ges_model, ges_identified_estimand, ges_estimate_linear_regression)\n",
    "print('ges_refutation_random: ', ges_refutation_random)\n",
    "\n",
    "# ges_do_causal_refute_estimate_placebo\n",
    "ges_res_placebo = do_causal_refute_estimate_placebo(ges_model, ges_identified_estimand, ges_estimate_linear_regression)\n",
    "print('ges_res_placebo: ', ges_res_placebo)\n",
    "\n",
    "# ges_do_causal_refute_estimate_subset\n",
    "ges_res_subset = do_causal_refute_estimate_subset(ges_model, ges_identified_estimand, ges_estimate_linear_regression)\n",
    "print('pc_res_subset: ', ges_res_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a50a51-6507-42fb-91b1-8d0709b146b0",
   "metadata": {},
   "source": [
    "### Lingam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e559eff-4354-425c-970f-126eddc37180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lingam DAG Causal Model\n",
    "lingam_model = create_causal_model(lingam_dot, df_encoded, treatment=\"Hours_Studied\", outcome=\"Exam_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7b786b7-0478-4048-a149-736ff2c6e46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimand type: EstimandType.NONPARAMETRIC_ATE\n",
      "\n",
      "### Estimand : 1\n",
      "Estimand name: backdoor\n",
      "Estimand expression:\n",
      "       d                       \n",
      "────────────────(E[Exam_Score])\n",
      "d[Hours_Studied]               \n",
      "Estimand assumption 1, Unconfoundedness: If U→{Hours_Studied} and U→Exam_Score then P(Exam_Score|Hours_Studied,,U) = P(Exam_Score|Hours_Studied,)\n",
      "\n",
      "### Estimand : 2\n",
      "Estimand name: iv\n",
      "No such variable(s) found!\n",
      "\n",
      "### Estimand : 3\n",
      "Estimand name: frontdoor\n",
      "No such variable(s) found!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lingam_identified_estimand\n",
    "lingam_identified_estimand = do_causal_identification(lingam_model)\n",
    "print(lingam_identified_estimand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136e44b-a755-41a5-83ed-68b303ee3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lingam_do_causal_estimation_propensity_score_stratification\n",
    "lingam_estimate_propensity_score = do_causal_estimation_propensity_score_stratification(lingam_model, lingam_identified_estimand)\n",
    "print(lingam_estimate_propensity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1167d7-dcb3-42b3-a480-ed05f2960fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lingam_do_causal_estimation_linear_regression\n",
    "lingam_estimate_linear_regression = do_causal_estimation_linear_regression(lingam_model, lingam_identified_estimand)\n",
    "print(lingam_estimate_linear_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53f2fc-6a51-4827-8525-094af0181105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lingam_do_causal_refute_estimate_random\n",
    "lingam_refutation_random = do_causal_refute_estimate_random(lingam_model, lingam_identified_estimand, lingam_estimate_linear_regression)\n",
    "print('lingam_refutation_random: ', lingam_refutation_random)\n",
    "\n",
    "# lingam_do_causal_refute_estimate_placebo\n",
    "lingam_res_placebo = do_causal_refute_estimate_placebo(lingam_model, lingam_identified_estimand, lingam_estimate_linear_regression)\n",
    "print('lingam_res_placebo: ', lingam_res_placebo)\n",
    "\n",
    "# lingam_do_causal_refute_estimate_subset\n",
    "lingam_res_subset = do_causal_refute_estimate_subset(lingam_model, lingam_identified_estimand, lingam_estimate_linear_regression)\n",
    "print('lingam_res_subset: ', lingam_res_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dd533-b782-4f8f-9baf-b4dbbf174df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
